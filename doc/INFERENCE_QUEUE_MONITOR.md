# AI推理队列监控功能

## 功能概述

在抽帧服务监控页面新增**AI推理队列监控**模块，实时显示图片丢弃率、队列堆积情况等关键指标，帮助及时发现推理能力不足的问题。

## 新增功能

### 1. 推理队列实时监控

#### 核心指标
- **队列大小**：当前待处理图片数 / 最大容量
- **队列使用率**：队列填充百分比
- **图片丢弃率**：累计丢弃图片占总图片的比例
- **平均推理时间**：单张图片平均处理时间

#### 统计数据
- **累计处理**：成功处理的图片总数
- **累计丢弃**：因队列满而丢弃的图片数
- **推理成功**：推理成功的次数
- **推理失败**：推理失败的次数

### 2. 智能告警提示

系统会根据关键指标自动显示告警：

#### 🔴 严重告警（红色）
- **队列使用率 > 80%** 且 **丢弃率 > 10%**
- 提示：推理队列严重堆积，建议立即处理

#### ⚠️ 警告（橙色）
- **队列使用率 > 80%**：队列堆积
- **丢弃率 > 10%**：图片丢弃率过高

#### ✅ 正常（绿色）
- **队列使用率 < 50%** 且 **丢弃率 < 10%**

### 3. 性能指标颜色编码

所有指标都使用颜色直观显示状态：
- 🟢 **绿色**：正常
- 🟡 **黄色**：需要关注
- 🔴 **红色**：严重问题

## 使用指南

### 访问监控页面
1. 导航至：**抽帧监控** 页面 (`/frame-extractor/monitor`)
2. 查看 **AI推理队列** 卡片

### 问题判断标准

#### 图片丢弃率过高
**现象**：图片丢弃率 > 10%

**原因**：
- AI算法服务实例不足
- 算法推理速度慢
- 抽帧频率过高，产生图片速度 > 处理速度

**解决方案**：
1. **增加算法服务实例**：启动更多算法服务进程
2. **降低抽帧频率**：减少每秒产生的图片数量
3. **优化算法性能**：检查算法服务是否有性能瓶颈
4. **增加队列容量**：在配置中调整 `max_queue_size`

#### 队列堆积严重
**现象**：队列使用率 > 80%

**原因**：
- 瞬时图片产生过多
- 推理处理速度跟不上

**解决方案**：
1. **增加并发数**：提高推理并发能力
2. **检查算法服务**：确认所有算法服务正常运行
3. **临时降低抽帧频率**：应急措施

#### 推理时间过长
**现象**：平均推理时间 > 3000ms

**原因**：
- 算法模型复杂度高
- 硬件资源不足（CPU/GPU）
- 网络延迟（算法服务在远程）

**解决方案**：
1. **优化模型**：使用更轻量的模型
2. **升级硬件**：增加GPU或更快的CPU
3. **本地部署**：将算法服务部署在同一网络

### 最佳实践

#### 1. 设定合理的抽帧频率
```
推荐配置：
- 实时监控场景：1-2秒/帧
- 一般监控场景：3-5秒/帧
- 低频监控场景：10-30秒/帧
```

#### 2. 算法服务实例数计算
```
公式：实例数 >= (抽帧任务数 × 1秒 / 抽帧间隔) / (1秒 / 平均推理时间)

示例：
- 10个任务，间隔3秒，平均推理1秒
- 实例数 >= (10 × 1/3) / (1/1) = 3.33
- 建议至少4个实例
```

#### 3. 监控频率设置
- **正常情况**：5-10秒刷新一次
- **调试阶段**：1-3秒刷新一次
- **稳定运行**：10-30秒刷新一次

## API接口

### 获取推理统计
```http
GET /ai_analysis/inference_stats

Response:
{
  "queue_size": 15,
  "queue_max_size": 100,
  "queue_utilization": 0.15,
  "dropped_total": 1234,
  "processed_total": 98765,
  "drop_rate": 0.0123,
  "strategy": "drop_oldest",
  "avg_inference_ms": 856.5,
  "max_inference_ms": 5420,
  "total_inferences": 98765,
  "failed_inferences": 42,
  "updated_at": "2025-10-21T10:30:00Z"
}
```

## 技术实现

### 后端
- **队列管理**：`internal/plugin/aianalysis/queue.go`
  - `InferenceQueue` - 智能队列
  - `GetStats()` - 获取统计信息
  - `GetDropRate()` - 计算丢弃率

- **服务层**：`internal/plugin/aianalysis/service.go`
  - `InferenceStats` - 统计数据结构
  - `GetInferenceStats()` - 获取推理统计

- **API层**：`internal/web/api/ai_analysis.go`
  - `GET /ai_analysis/inference_stats` - 统计接口

### 前端
- **监控页面**：`web-src/src/views/frame-extractor/monitor.vue`
  - AI推理队列卡片
  - 实时统计展示
  - 智能告警提示

## 故障排查

### 1. 监控数据不显示
**可能原因**：
- AI分析插件未启用
- 算法服务未注册

**解决方法**：
1. 检查 `config.toml` 中 `ai_analysis.enable = true`
2. 确认至少有一个算法服务已注册
3. 查看后端日志确认服务启动

### 2. 丢弃率一直增长
**紧急处理**：
```bash
# 1. 立即增加算法服务实例
python examples/yolo_algorithm_service.py --port 8001 &
python examples/yolo_algorithm_service.py --port 8002 &

# 2. 临时停止部分抽帧任务
# 在前端页面停止不重要的任务

# 3. 降低抽帧频率
# 在抽帧管理页面调整间隔为更大值
```

### 3. 推理时间异常
**诊断步骤**：
1. 检查算法服务日志
2. 测试算法服务响应时间
3. 检查网络延迟
4. 监控硬件资源使用

## 性能优化建议

### 1. 队列策略选择
- **drop_oldest**（推荐）：丢弃最旧的图片，保证最新数据被处理
- **drop_newest**：丢弃新图片，适合需要按时序处理的场景
- **latest_only**：清空队列只保留最新，适合只关心当前状态的场景

### 2. 队列容量设置
```toml
# 根据场景调整队列大小
# 配置位置：代码中的 NewInferenceQueue 调用
queue_max_size = 100  # 默认值
queue_max_size = 200  # 高峰场景
queue_max_size = 50   # 低延迟需求
```

### 3. 监控告警阈值
- **队列告警阈值**：建议设置为队列容量的 50%
- **丢弃率告警**：建议 > 5% 时开始关注
- **推理时间告警**：建议 > 3000ms 时告警

## 后续优化方向

- [ ] 添加历史趋势图表（队列大小、丢弃率随时间变化）
- [ ] 支持按任务类型统计丢弃情况
- [ ] 添加推理性能热力图
- [ ] 实现自动扩缩容建议
- [ ] 支持WebSocket实时推送告警

## 相关文档

- [抽帧服务监控](./FRAME_EXTRACTOR_MONITOR.md)
- [AI分析配置指南](./doc/AI_ANALYSIS.md)
- [算法服务对接](./ALGORITHM_SERVICE_INTEGRATION_GUIDE.md)

