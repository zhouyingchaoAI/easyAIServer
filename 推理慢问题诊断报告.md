# 推理慢问题诊断报告

## 问题概述

推理队列积压严重，图片在队列中等待时间过长，导致大量图片被清理。

## 诊断结果

### 1. 关键问题

#### 问题1：Worker数量被硬编码限制 ⚠️ **已修复**
- **配置值**：`max_concurrent_infer = 300`
- **实际值**：被硬编码限制为 200
- **影响**：无法充分利用配置的并发数，导致推理速度受限
- **修复**：已移除硬编码限制，现在可以使用配置的300个worker

#### 问题2：队列积压严重 ❌
- **当前状态**：队列大小 49990/50000 (99.98%)
- **图片丢失**：1195次（图片在队列中等待时间过长被清理）
- **原因**：推理速度跟不上图片生成速度
- **影响**：大量图片在队列中等待，最终被清理机制删除

#### 问题3：推理统计异常 ⚠️
- **总推理次数**：0（但之前有成功记录）
- **平均推理时间**：0ms
- **可能原因**：统计被重置或推理失败

### 2. 当前性能指标

- **队列使用率**：99.98%（严重积压）
- **已处理总数**：321
- **算法服务数**：24个
- **平均响应时间**：107ms（最快73ms，最慢142ms）
- **调用次数**：1287-1942次/服务

### 3. 根本原因分析

1. **并发数不足**：虽然配置了300个worker，但被限制为200，导致处理能力不足
2. **图片生成速度过快**：抽帧间隔0.2秒，生成速度约5张/秒/任务
3. **推理速度跟不上**：即使有24个算法服务，平均响应时间107ms，理论最大吞吐量约224张/秒，但实际可能更低
4. **队列容量限制**：50000的队列在积压情况下很快被填满

## 优化方案

### 方案1：移除Worker限制 ✅ **已完成**
- 已移除硬编码的200限制
- 现在可以使用配置的300个worker
- **预期提升**：处理能力提升50%

### 方案2：增加队列大小（推荐）
```toml
[ai_analysis]
max_queue_size = 100000  # 从50000增加到100000
```
- **优点**：可以缓冲更多图片，减少丢失
- **缺点**：占用更多内存

### 方案3：增加并发数（如果资源允许）
```toml
[ai_analysis]
max_concurrent_infer = 500  # 从300增加到500
```
- **优点**：进一步提升处理能力
- **缺点**：需要更多CPU/网络资源

### 方案4：减少抽帧频率（如果实时性要求不高）
```toml
[[frame_extractor.tasks]]
interval_ms = 500  # 从200增加到500
```
- **优点**：减少图片生成速度，降低队列压力
- **缺点**：可能错过某些关键帧

### 方案5：优化算法服务性能
- 检查算法服务CPU/GPU使用率
- 考虑使用更快的模型或硬件
- 优化算法服务代码

## 建议的优化步骤

1. ✅ **立即执行**：移除Worker限制（已完成）
2. **短期优化**：增加队列大小到100000
3. **中期优化**：如果资源允许，增加并发数到500
4. **长期优化**：优化算法服务性能，或考虑减少抽帧频率

## 监控指标

建议持续监控以下指标：
- 队列使用率（目标：< 80%）
- 图片丢失次数（目标：0）
- 平均推理时间（目标：< 200ms）
- 推理成功率（目标：> 99%）

## 验证方法

修复后，运行以下命令验证：
```bash
# 查看队列状态
curl http://localhost:5066/api/v1/ai_analysis/inference_stats | python3 -m json.tool

# 运行性能分析
./scripts/analyze_inference_performance.sh
```

## 注意事项

1. 增加并发数会增加系统资源消耗，需要确保服务器有足够的CPU和网络带宽
2. 队列大小增加会占用更多内存，需要监控内存使用情况
3. 如果推理速度仍然跟不上，可能需要考虑减少抽帧频率或增加算法服务实例

